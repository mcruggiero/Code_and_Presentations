{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`this notebook took from the below link and edited upon to our subject`\n",
    "https://github.com/balak4/Optimizing-Evac-Routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4194895c-aee6-4007-952d-9f8e8f28b890"
    }
   },
   "source": [
    "# \"Historical\" Tweets - from Twitter Search API using Tweepy Library <br>\n",
    "\n",
    "_Authors: Amy Taylor and Veronica Giannotta_ <br> <br>\n",
    "Preliminary steps before using Twitter's API:\n",
    "1. Sign-up for a twitter account\n",
    "2. Register a twitter developer account (requires email or phone number)\n",
    "3. Create a developer app (I went with the name BlockedRoads)\n",
    "4. Obtain your 'Access token' and 'access token secret' in the developer dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "7a35bd4f-64b7-4da2-b5d6-07f879c10654"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import shutil\n",
    "import jsonpickle\n",
    "import json\n",
    "import datetime\n",
    "import config\n",
    "\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "91702dbc-8243-4d9b-b081-8e94def65aa0"
    }
   },
   "source": [
    "## Part 1: Prepare API credentials\n",
    "**Step 1: Authenticate account and tokens through tweepy**\n",
    "<br>Required credentials:\n",
    "<br>`config.consumer_key` = 'bVbkbDedhEgR3li5ryFhEGqaY'\n",
    "<br>`config.consumer_secret` = 'QECkiza2M9rGQomcSdkvIlnhKpQpEJQogYE5RvZcvfFhnQuTfp'\n",
    "<br>`config.access_token` = '81792373-fdAnWAHmnnmLD0wtaM4UuTCMtPaWZnm2okuK1ekwv '\n",
    "<br>`config.access_token_secret` = 'Gbw5KLPVE0jL87MgyVg1shGgbfyM3kylSuzU0F7KqAFDl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.consumer_key = 'cP0BqCOcEt7B1TsWa1W5EdK58'\n",
    "config.consumer_secret = 'kbsOvwUGjBjyFt4kLSyIz1PFhqinKVt3dI91Mh4VCPsss3QIOi'\n",
    "config.access_token = '81792373-cAKBuhV6SxKNFNppGzEey6NxkAqfOPycSWfxQslTI'\n",
    "config.access_token_secret = '6FaTYiK7pn4ji2lMs8GnzA1VwGYGlhOekhxgPhCdu4lpa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "f3323f68-62bf-423c-91b0-4eeac028887d"
    }
   },
   "outputs": [],
   "source": [
    "# authenticate account with tweepy\n",
    "auth = tweepy.OAuthHandler(config.consumer_key, config.consumer_secret)\n",
    "auth.set_access_token(config.access_token, config.access_token_secret)\n",
    "# auth.set_access_token(config.access_key, config.access_secret) # this is the original code but i edited as above\n",
    "\n",
    "\n",
    "# create API object to pull data from twitter - and pass in authentication code\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are free to make Twitter API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "002aa9a8-0d8e-473d-b03d-ee3e6f484206"
    }
   },
   "source": [
    "**Step 2: Verify API is working with your account**\n",
    "- Run this cell to check if program is working. Output is your twitter name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "d48ad373-eefb-4c94-ad15-20ef63e0f969"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cengiz imga\n"
     ]
    }
   ],
   "source": [
    "user = api.me()\n",
    "print (user.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e0814491-a723-400c-bf53-51c4d43f7f72"
    }
   },
   "source": [
    "**Step 3: Use geo_search API to get the `place_id` for a particular location**\n",
    "- `place_id` is a unique id created by Twitter that is assigned to different neighborhoods/cities/countries\n",
    "- In the query parameter, type the name of the city or country you want the place_id for\n",
    "- granularity = neighborhood (default) , city , admin or country\n",
    "    - EX: when query = 'Boston', the place_id generated is the same for neighborhood or city ( but empty for country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "nbpresent": {
     "id": "45273621-1fac-402e-803d-4678436ad7b7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 th full name is: Medford, MA\n",
      "place_id is:  c8e7273a81fab7c0\n",
      "2 th full name is: Arlington, MA\n",
      "place_id is:  47aff34722fae115\n",
      "0 th full name is: Somerville, MA\n",
      "place_id is:  ae845a49091f2727\n",
      "0 th full name is: Malden, MA\n",
      "place_id is:  75f5a403163f6f95\n",
      "0 th full name is: Stoneham, MA\n",
      "place_id is:  8c16a23215a1b4b3\n",
      "1 th full name is: Everett, MA\n",
      "place_id is:  fa48d6b6ccab7579\n",
      "['c8e7273a81fab7c0', '47aff34722fae115', 'ae845a49091f2727', '75f5a403163f6f95', '8c16a23215a1b4b3', 'fa48d6b6ccab7579']\n"
     ]
    }
   ],
   "source": [
    "#  Determine the city, country, or location you want\n",
    "\n",
    "l=[ 'Medford', \n",
    "    'Arlington',\n",
    "    'Somerville',\n",
    "    'Malden',\n",
    "    'Winchester',\n",
    "    'Stoneham',\n",
    "    'Everett'          \n",
    "              ]\n",
    "l2 = []\n",
    "for i in l:\n",
    "    places = api.geo_search(query=i, \n",
    "                            granularity=\"city\")\n",
    "# i edited code by adding for loop in order to find if there is any other city(here Medford for me) in other states\n",
    "    for j in range(3):\n",
    "        place_id = places[j].id\n",
    "        if places[j].full_name==i+', MA':\n",
    "            print(j,'th full name is:', places[j].full_name)\n",
    "            print('place_id is: ',place_id)\n",
    "            l2.append(place_id)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Place(_api=<tweepy.api.API object at 0x10d6d25f8>, id='01ca054566a48dad', url='https://api.twitter.com/1.1/geo/id/01ca054566a48dad.json', place_type='city', name='Everett', full_name='Everett, PA', country_code='US', country='United States', contained_within=[Place(_api=<tweepy.api.API object at 0x10d6d25f8>, id='c21da2b2ed4e3be2', url='https://api.twitter.com/1.1/geo/id/c21da2b2ed4e3be2.json', place_type='admin', name='JOHNSTOWN-ALTOONA-ST COLGE', full_name='JOHNSTOWN-ALTOONA-ST COLGE', country_code='', country='', centroid=[-78.25877922237933, 40.675733], bounding_box=BoundingBox(_api=<tweepy.api.API object at 0x10d6d25f8>, type='Polygon', coordinates=[[[-79.417553, 39.721578], [-79.417553, 41.629888], [-77.1438, 41.629888], [-77.1438, 39.721578], [-79.417553, 39.721578]]]), attributes={})], centroid=[-78.37116810657294, 40.031429], bounding_box=BoundingBox(_api=<tweepy.api.API object at 0x10d6d25f8>, type='Polygon', coordinates=[[[-78.386849, 40.006168], [-78.386849, 40.05669], [-78.347186, 40.05669], [-78.347186, 40.006168], [-78.386849, 40.006168]]]), attributes={})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3d81091c-aa07-4527-8bbe-ddd027322e49"
    }
   },
   "source": [
    "***List of search queries made:***\n",
    "<br>NOTE: there must be no space between place and place_ID\n",
    "\n",
    "    \n",
    "|searchQuery| place ID |granularity| file | # of tweets| extended tweet? |\n",
    "|---|---|---|---|---|---|\n",
    "|'place:96683cc9126741d1 road closed' | USA |country| ./PoGo_USA_Tutorial.json20190114_7_1_36.json | 142 | - |\n",
    "| 'place:1c69a67ad480e1b1 road closed' | Houston | city/neigh | ./historical_20190114_11_59.json| 15|- |\n",
    "| 'Houston road closed' | NA | NA | ./historical_20190114_12_2.json | 9|- |\n",
    "|'place:96683cc9126741d1 road closed' | USA |city| ./historical_20190115_14_57.json | 210 | yes |\n",
    "|'place:1c69a67ad480e1b1 road closed' | Houston |city| ./historical_20190117_11_49.json | 13 | no |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "74feb20b-8bdb-403b-bf7e-4f17039f87f9"
    }
   },
   "source": [
    "## Part 2: Download Archived Tweets with the Search API\n",
    "**Step 1: Use tweepy library to download tweets from Search API based on our query search terms, and save tweets as a json file**\n",
    " - Include a place ID in the query if necessary\n",
    " - Other search params that are optional: since='2019-01-03',until='2019-01-11'\n",
    " \n",
    "useful resource: http://www.dealingdata.net/2016/07/23/PoGo-Series-Tweepy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'c8e7273a81fab7c0', '47aff34722fae115',\n",
    "'ae845a49091f2727', '75f5a403163f6f95', '8c16a23215a1b4b3', 'fa48d6b6ccab7579"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "nbpresent": {
     "id": "faf6dc51-2b8f-40a1-b142-e978b42abe32"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 tweets\n"
     ]
    }
   ],
   "source": [
    "searchQuery = 'place: c8e7273a81fab7c0 OR place: aff34722fae115 OR'\n",
    "'place: ae845a49091f2727 OR place: 75f5a403163f6f95 OR' \n",
    "'place: 8c16a23215a1b4b3 OR place: fa48d6b6ccab7579 OR' \n",
    "'#roadclosed OR #roadaccident OR #roadblock OR \"road closed\" OR'\n",
    "'\"road accident\" OR \"wreck\" OR \"road block\" OR \"road construction\"'\n",
    "'OR \"roadway reduced\" OR \"one lane\"'\n",
    "\n",
    "tweetCount = 0\n",
    "\n",
    "#Open a text file to save the tweets to\n",
    "with open('../cimga/historical.json', 'w') as f:\n",
    "\n",
    "    #Tell the Cursor method: we want to use Search API (api.search), and our query\n",
    "    for tweet in tweepy.Cursor(api.search,q=searchQuery,\n",
    "#                                tweet_mode='extended'    #comment out extended tweet if desired\n",
    "                              ).items() :         \n",
    "\n",
    "        #Verify the tweet has place info before writing \n",
    "        if tweet.place is not None:\n",
    "            \n",
    "            #Write the JSON format to the text file, and add one to the number of tweets we've collected\n",
    "            f.write(jsonpickle.encode(tweet._json, unpicklable=False) + '\\n')\n",
    "            tweetCount += 1\n",
    "\n",
    "    #Display how many tweets we have collected\n",
    "    print(\"Downloaded {0} tweets\".format(tweetCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm at @DICKS Sporting Goods in Medford, MA https://t.co/JzoUdqhxlU\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2477087a-0b4e-4ccd-b439-f14993ad71d5"
    }
   },
   "source": [
    "**Step 2: Append a timestamp to the end of the json file name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 4, 16, 20, 53, 34, 457163)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now=datetime.datetime.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "nbpresent": {
     "id": "e30fcb1c-2794-48ea-990c-a55b58cc25a0"
    }
   },
   "outputs": [],
   "source": [
    "def file_conversion():\n",
    "    #create a timestamp\n",
    "    now = datetime.datetime.now()\n",
    "    month = '0'+str(now.month)\n",
    "    day = str(now.day)\n",
    "    hour = str(now.hour)\n",
    "    minute = str(now.minute)\n",
    "    now_str = str(now.year)+month+day+'_'+hour+'_'+minute\n",
    "    \n",
    "    \n",
    "    #replace the name of our file with a new timestamped filename\n",
    "    dest = '../cimga/historical_' + now_str + \".json\"\n",
    "    shutil.move('../cimga/historical.json', dest)\n",
    "    \n",
    "    with open(dest, \"r\") as f:\n",
    "        status = f.readlines()\n",
    "        jsons = []\n",
    "        for ind in status:\n",
    "            jsons.append(json.loads(ind))\n",
    "    return jsons\n",
    "\n",
    "# Uncomment out the file_conversion function to activate the file name change\n",
    "# file_conversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_conversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "604a2b09-df0a-4641-9f30-de3883532c10"
    }
   },
   "source": [
    "**Step 3: Add the newly created json file to the list below for easy access later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "nbpresent": {
     "id": "4558b66b-a4e5-4393-a52d-3495ccd09777"
    }
   },
   "outputs": [],
   "source": [
    "# Previously created json files can be accessed from this list\n",
    "\n",
    "# json_df = pd.read_json(\"../data/AT_historical/PoGo_USA_Tutorial.json20190114_7_1_36.json\", lines = True)\n",
    "# json_df = pd.read_json(\"../data/AT_historical/historical_20190114_11_59.json\", lines = True)\n",
    "# json_df = pd.read_json(\"../data/AT_historical/historical_20190114_12_2.json\", lines = True)\n",
    "# json_df = pd.read_json(\"../data/AT_historical/historical_20190115_14_57.json\", lines = True)\n",
    "json_df = pd.read_json(\"../cimga/historical_20190415_21_9.json\", lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "63b26ce2-424c-477f-b326-4192259183a1"
    }
   },
   "source": [
    "# Part 3: Explore Tweets from json file\n",
    "### Option A: Tweets --> json file --> dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "nbpresent": {
     "id": "1331211f-697e-4313-9f0a-1f72be4ce9b9"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['contributors', 'coordinates', 'created_at', 'entities',\n",
       "       'favorite_count', 'favorited', 'geo', 'id', 'id_str',\n",
       "       'in_reply_to_screen_name', 'in_reply_to_status_id',\n",
       "       'in_reply_to_status_id_str', 'in_reply_to_user_id',\n",
       "       'in_reply_to_user_id_str', 'is_quote_status', 'lang', 'metadata',\n",
       "       'place', 'possibly_sensitive', 'retweet_count', 'retweeted', 'source',\n",
       "       'text', 'truncated', 'user'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of columns currently available in our dataframe\n",
    "json_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6f7b551a-9066-466a-9154-696449bd61eb"
    }
   },
   "source": [
    "**View all tweets from the `text` column** (for the first 7 tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "nbpresent": {
     "id": "1cca9458-0901-41ed-a839-785953e4a4e6"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Why ainâ€™t nobody tell me that this Old Town Road Remix slapped like that? ðŸ¤­\n",
      "1 Road construction, roadway reduced to one lane in #Medford on Rt-16 Both EB/WB between Rt-28 and Rt-99 #traffic https://t.co/AoTr5OKtFq\n",
      "2 Road closed intermittently in #Medford on Rt-16 Both EB/WB between Rt-28 and Rt-99 #traffic https://t.co/AoTr5OKtFq\n",
      "3 @Tri_Merch Was it a road ride? If so,why?\n",
      "4 Iâ€™ll say it. Am I being memeâ€™d by the Old Town Road song?\n"
     ]
    }
   ],
   "source": [
    "list = json_df.loc[:10, 'text']\n",
    "for i in range(len(list)):\n",
    "    print(i, list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1120b283-c3e2-4ba7-8e39-d8b95f7c7695"
    }
   },
   "source": [
    "Explore attributes of the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "nbpresent": {
     "id": "6f7023e3-1de4-46b8-87a6-eca216601564"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_api\n",
      "_json\n",
      "author\n",
      "contributors\n",
      "coordinates\n",
      "created_at\n",
      "destroy\n",
      "entities\n",
      "favorite\n",
      "favorite_count\n",
      "favorited\n",
      "geo\n",
      "id\n",
      "id_str\n",
      "in_reply_to_screen_name\n",
      "in_reply_to_status_id\n",
      "in_reply_to_status_id_str\n",
      "in_reply_to_user_id\n",
      "in_reply_to_user_id_str\n",
      "is_quote_status\n",
      "lang\n",
      "metadata\n",
      "parse\n",
      "parse_list\n",
      "place\n",
      "possibly_sensitive\n",
      "retweet\n",
      "retweet_count\n",
      "retweeted\n",
      "retweets\n",
      "source\n",
      "source_url\n",
      "text\n",
      "truncated\n",
      "user\n"
     ]
    }
   ],
   "source": [
    "def PrintMembers(obj):\n",
    "    for attribute in dir(obj):\n",
    "        #We don't want to show built in methods of the class\n",
    "        if not attribute.startswith('__'):\n",
    "            print(attribute)\n",
    "PrintMembers(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shrink dataframe down to only the useful columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "nbpresent": {
     "id": "18d07bce-7783-46d7-9cfc-39c8f5e131d7"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>geo</th>\n",
       "      <th>place</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2019-04-15 04:30:33</td>\n",
       "      <td>None</td>\n",
       "      <td>{'attributes': {}, 'bounding_box': {'coordinat...</td>\n",
       "      <td>Why ainâ€™t nobody tell me that this Old Town Ro...</td>\n",
       "      <td>{'contributors_enabled': False, 'created_at': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'coordinates': [-71.08259, 42.40478], 'type':...</td>\n",
       "      <td>2019-04-07 16:18:16</td>\n",
       "      <td>{'coordinates': [42.40478, -71.08259], 'type':...</td>\n",
       "      <td>{'attributes': {}, 'bounding_box': {'coordinat...</td>\n",
       "      <td>Road construction, roadway reduced to one lane...</td>\n",
       "      <td>{'contributors_enabled': False, 'created_at': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'coordinates': [-71.08259, 42.40478], 'type':...</td>\n",
       "      <td>2019-04-07 15:45:31</td>\n",
       "      <td>{'coordinates': [42.40478, -71.08259], 'type':...</td>\n",
       "      <td>{'attributes': {}, 'bounding_box': {'coordinat...</td>\n",
       "      <td>Road closed intermittently in #Medford on Rt-1...</td>\n",
       "      <td>{'contributors_enabled': False, 'created_at': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>2019-04-06 22:37:43</td>\n",
       "      <td>None</td>\n",
       "      <td>{'attributes': {}, 'bounding_box': {'coordinat...</td>\n",
       "      <td>@Tri_Merch Was it a road ride? If so,why?</td>\n",
       "      <td>{'contributors_enabled': False, 'created_at': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>2019-04-06 14:48:36</td>\n",
       "      <td>None</td>\n",
       "      <td>{'attributes': {}, 'bounding_box': {'coordinat...</td>\n",
       "      <td>Iâ€™ll say it. Am I being memeâ€™d by the Old Town...</td>\n",
       "      <td>{'contributors_enabled': False, 'created_at': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         coordinates          created_at  \\\n",
       "0                                               None 2019-04-15 04:30:33   \n",
       "1  {'coordinates': [-71.08259, 42.40478], 'type':... 2019-04-07 16:18:16   \n",
       "2  {'coordinates': [-71.08259, 42.40478], 'type':... 2019-04-07 15:45:31   \n",
       "3                                               None 2019-04-06 22:37:43   \n",
       "4                                               None 2019-04-06 14:48:36   \n",
       "\n",
       "                                                 geo  \\\n",
       "0                                               None   \n",
       "1  {'coordinates': [42.40478, -71.08259], 'type':...   \n",
       "2  {'coordinates': [42.40478, -71.08259], 'type':...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                               place  \\\n",
       "0  {'attributes': {}, 'bounding_box': {'coordinat...   \n",
       "1  {'attributes': {}, 'bounding_box': {'coordinat...   \n",
       "2  {'attributes': {}, 'bounding_box': {'coordinat...   \n",
       "3  {'attributes': {}, 'bounding_box': {'coordinat...   \n",
       "4  {'attributes': {}, 'bounding_box': {'coordinat...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Why ainâ€™t nobody tell me that this Old Town Ro...   \n",
       "1  Road construction, roadway reduced to one lane...   \n",
       "2  Road closed intermittently in #Medford on Rt-1...   \n",
       "3          @Tri_Merch Was it a road ride? If so,why?   \n",
       "4  Iâ€™ll say it. Am I being memeâ€™d by the Old Town...   \n",
       "\n",
       "                                                user  \n",
       "0  {'contributors_enabled': False, 'created_at': ...  \n",
       "1  {'contributors_enabled': False, 'created_at': ...  \n",
       "2  {'contributors_enabled': False, 'created_at': ...  \n",
       "3  {'contributors_enabled': False, 'created_at': ...  \n",
       "4  {'contributors_enabled': False, 'created_at': ...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['coordinates', 'created_at', 'geo', 'place', 'text', 'user']\n",
    "df = json_df.loc[:, columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e53e9039-09c2-4504-9f9f-32c594225414"
    }
   },
   "source": [
    "### Explore some features of the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "nbpresent": {
     "id": "dad3dbf3-f957-4c8c-9edf-6c198210db12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'attributes': {}, 'bounding_box': {'coordinates': [[[-71.149807, 42.396145], [-71.071833, 42.396145], [-71.071833, 42.453759], [-71.149807, 42.453759]]], 'type': 'Polygon'}, 'contained_within': [], 'country': 'United States', 'country_code': 'US', 'full_name': 'Medford, MA', 'id': 'c8e7273a81fab7c0', 'name': 'Medford', 'place_type': 'city', 'url': 'https://api.twitter.com/1.1/geo/id/c8e7273a81fab7c0.json'}\n",
      "--------\n",
      "1 {'attributes': {}, 'bounding_box': {'coordinates': [[[-71.149807, 42.396145], [-71.071833, 42.396145], [-71.071833, 42.453759], [-71.149807, 42.453759]]], 'type': 'Polygon'}, 'contained_within': [], 'country': 'United States', 'country_code': 'US', 'full_name': 'Medford, MA', 'id': 'c8e7273a81fab7c0', 'name': 'Medford', 'place_type': 'city', 'url': 'https://api.twitter.com/1.1/geo/id/c8e7273a81fab7c0.json'}\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# see all the nested information within place (for the first two tweets)\n",
    "list = json_df.loc[:1, 'place']\n",
    "for i in range(len(list)):\n",
    "    print(i, list[i])\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The dataframe that we have now has many attributes nested within other attributes. If we want to access the corrdinates nested within `coordinates` or the city nested within `place` we will need to unpack these variables using a different method. Use the next section to convert nested values into their own columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "cc9056f7-00b1-42d9-aa5c-a1b65ca2d047"
    }
   },
   "source": [
    "## Option B. Tweets --> json --> parsed --> nested dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "nbpresent": {
     "id": "ceb62c40-fdc4-4657-a359-47dbf4b53ba3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Could not parse:  0\n"
     ]
    }
   ],
   "source": [
    "# Read in json file\n",
    "json_df = pd.read_json(\"../cimga/historical_20190415_21_9.json\", lines = True)\n",
    "\n",
    "# convert json file to list of dictionaries\n",
    "tweets_data = []\n",
    "notParsed = []\n",
    "tweets_file = open(\"../cimga/historical_20190415_21_9.json\",\"r\")\n",
    "for line in tweets_file:    \n",
    "    if line.strip():    \n",
    "        try:\n",
    "            tweet=json.loads(line)\n",
    "            tweets_data.append(tweet)\n",
    "        except:\n",
    "            notParsed.append(line)\n",
    "            continue\n",
    "print(len(tweets_data))\n",
    "print('Could not parse: ', len(notParsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "27af0d00-bbf2-454c-94fc-808ebdfc4a04"
    }
   },
   "source": [
    "**Unpack the nested columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "nbpresent": {
     "id": "c1f5bafe-1e87-485e-8993-e3c19e043381"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time_zone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-2110b95f3739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# This method looks for any instances of nested dictionaries (DOES NOT FLATTEN LISTS)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msample_tweets_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_tweets_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msample_tweets_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/json/normalize.py\u001b[0m in \u001b[0;36mjson_normalize\u001b[0;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# TODO: handle record value which are lists, at least error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m#       reasonably\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_to_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/json/normalize.py\u001b[0m in \u001b[0;36mnested_to_record\u001b[0;34m(ds, prefix, sep, level)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnew_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_to_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mnew_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/io/json/normalize.py\u001b[0m in \u001b[0;36mnested_to_record\u001b[0;34m(ds, prefix, sep, level)\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mnew_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pop the key if the value is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mnew_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time_zone'"
     ]
    }
   ],
   "source": [
    "tweet_cols = ['coordinates', 'created_at', \n",
    "#                'full_text',\n",
    "              'text','geo', 'id', 'place', 'user']\n",
    "\n",
    "sample_tweets_dict = [{col:tweet[col] for col in tweet_cols } for tweet in tweets_data]\n",
    "\n",
    "# This method looks for any instances of nested dictionaries (DOES NOT FLATTEN LISTS)\n",
    "sample_tweets_df = pd.io.json.json_normalize(sample_tweets_dict)\n",
    "\n",
    "sample_tweets_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_tweets_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-7b13fb7b6178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_tweets_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_tweets_df' is not defined"
     ]
    }
   ],
   "source": [
    "sample_tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the USA (or Houston) historical json file as df, COMMENT OUT\n",
    "# df = sample_tweets_df\n",
    "# df.to_csv(\"../data/AT_historical/USA_142tweets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine who the most common tweets are coming from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TotalTrafficDFW    16\n",
       "TotalTrafficABQ    13\n",
       "TotalTrafficMIA    10\n",
       "TotalTrafficPHX     8\n",
       "AlgoTraffic         7\n",
       "Name: user.screen_name, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tweets_df['user.screen_name'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the Twitter user \"TotalTraffic\", specific to a certain city, is contributing the most tweets to situations with \"road closed\", and providing location place data for each tweet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
