{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Image-Test\" data-toc-modified-id=\"Image-Test-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Image Test</a></span></li><li><span><a href=\"#Image-Size\" data-toc-modified-id=\"Image-Size-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Image Size</a></span></li><li><span><a href=\"#Array-View\" data-toc-modified-id=\"Array-View-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Array View</a></span></li><li><span><a href=\"#Tensor-View\" data-toc-modified-id=\"Tensor-View-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Tensor View</a></span></li></ul></li><li><span><a href=\"#Make-dataframe-with-all-files\" data-toc-modified-id=\"Make-dataframe-with-all-files-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Make dataframe with all files</a></span></li><li><span><a href=\"#Train-Test-Split\" data-toc-modified-id=\"Train-Test-Split-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Train Test Split</a></span></li><li><span><a href=\"#Traditional-Methods\" data-toc-modified-id=\"Traditional-Methods-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Traditional Methods</a></span></li><li><span><a href=\"#Pytorch-CNN\" data-toc-modified-id=\"Pytorch-CNN-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Pytorch CNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-Folder\" data-toc-modified-id=\"Training-Folder-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Training Folder</a></span></li><li><span><a href=\"#Test-Folder\" data-toc-modified-id=\"Test-Folder-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Test Folder</a></span></li><li><span><a href=\"#Labels-and-Parameters\" data-toc-modified-id=\"Labels-and-Parameters-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Labels and Parameters</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:05:19.643392Z",
     "start_time": "2019-08-14T03:05:18.935778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# usual suspects\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import requests\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cycler import cycler\n",
    "\n",
    "# the good stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# standard sklearn import\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# minor changes to plotting functions\n",
    "import matplotlib.pyplot as plt\n",
    "cmap=plt.cm.tab10\n",
    "c = cycler('color', cmap(np.linspace(0,1,10)))\n",
    "plt.rcParams[\"axes.prop_cycle\"] = c\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# change margin size of jupyter notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:05:21.212697Z",
     "start_time": "2019-08-14T03:05:21.201727Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = \"./data/Futurama/character02/0326_16.png\"\n",
    "image = Image.open(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:05:21.866730Z",
     "start_time": "2019-08-14T03:05:21.861244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAABpAQAAAAAR+TCXAAABSklEQVR4nOXTMU7DQBCF4X83UXCBwGWKSPgIOYKPkiNQ0rGhouQInAQZKQfIESyUIh2RSGGiOENhx5nHBSjY7tM8e2ftnWC4tYzI+ltaLjxp9ajcKmtlNdeNKuFSwhaFp7Fwnwl3v3qeC+tSWCVPG7YlAocobMbCXSas50JK4XsSPuFpANnAy/EgwjETNrmQQrgGaAaWpa8ayfMU8DxGYXMtJBfuCmGNsHrXri5XASILDp5TrHS8Sqz8s49VK68qLp1EIGfveZvadLaZWcOdmZlZigATNi5MqIe0deku3oWZnBvvGFLfeP+hHrAEEPqBDeGEG9hm4sM0mXCde1pZeB7629NzG5JnMXFH4Jup5/b8LzoWI3/elpnnhoXn6yg5tmm4ABFYyRy1Zagcj9zguL1kifAxqjzfZoMYw8snvvqFcKx8Vt4r+U/8AUa9aqCFZn4/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=1 size=105x105 at 0x7F09300857B8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:05:23.094042Z",
     "start_time": "2019-08-14T03:05:23.090314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 105)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omni_dim = image.size\n",
    "###\n",
    "#DO THIS: Find better syntax for calling the dimensions of the images\n",
    "###\n",
    "omni_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:05:51.308798Z",
     "start_time": "2019-08-14T03:05:51.300652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(img_path).convert(\"L\")\n",
    "img = np.array(img)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:05:53.076535Z",
     "start_time": "2019-08-14T03:05:53.072966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:05:53.896068Z",
     "start_time": "2019-08-14T03:05:53.892664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:05:56.828000Z",
     "start_time": "2019-08-14T03:05:56.804594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = transforms.ToTensor()(image).unsqueeze(0) # unsqueeze to add artificial first dimension\n",
    "image = Variable(image)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:05:57.384122Z",
     "start_time": "2019-08-14T03:05:57.375375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 105, 105])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataframe with all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:06:19.042750Z",
     "start_time": "2019-08-14T03:06:03.830089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>char</th>\n",
       "      <th>file</th>\n",
       "      <th>path</th>\n",
       "      <th>image_array</th>\n",
       "      <th>image_tensor</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Futurama</td>\n",
       "      <td>character02</td>\n",
       "      <td>0326_20.png</td>\n",
       "      <td>./data/Futurama/character02/0326_20.png</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>[[[tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.,...</td>\n",
       "      <td>Futurama_character02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Futurama</td>\n",
       "      <td>character02</td>\n",
       "      <td>0326_04.png</td>\n",
       "      <td>./data/Futurama/character02/0326_04.png</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>[[[tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.,...</td>\n",
       "      <td>Futurama_character02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Futurama</td>\n",
       "      <td>character02</td>\n",
       "      <td>0326_09.png</td>\n",
       "      <td>./data/Futurama/character02/0326_09.png</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>[[[tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.,...</td>\n",
       "      <td>Futurama_character02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Futurama</td>\n",
       "      <td>character02</td>\n",
       "      <td>0326_15.png</td>\n",
       "      <td>./data/Futurama/character02/0326_15.png</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>[[[tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.,...</td>\n",
       "      <td>Futurama_character02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Futurama</td>\n",
       "      <td>character02</td>\n",
       "      <td>0326_11.png</td>\n",
       "      <td>./data/Futurama/character02/0326_11.png</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>[[[tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.,...</td>\n",
       "      <td>Futurama_character02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language         char         file  \\\n",
       "0  Futurama  character02  0326_20.png   \n",
       "1  Futurama  character02  0326_04.png   \n",
       "2  Futurama  character02  0326_09.png   \n",
       "3  Futurama  character02  0326_15.png   \n",
       "4  Futurama  character02  0326_11.png   \n",
       "\n",
       "                                      path  \\\n",
       "0  ./data/Futurama/character02/0326_20.png   \n",
       "1  ./data/Futurama/character02/0326_04.png   \n",
       "2  ./data/Futurama/character02/0326_09.png   \n",
       "3  ./data/Futurama/character02/0326_15.png   \n",
       "4  ./data/Futurama/character02/0326_11.png   \n",
       "\n",
       "                                         image_array  \\\n",
       "0  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "1  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "2  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "3  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "4  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "\n",
       "                                        image_tensor                target  \n",
       "0  [[[tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.,...  Futurama_character02  \n",
       "1  [[[tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.,...  Futurama_character02  \n",
       "2  [[[tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.,...  Futurama_character02  \n",
       "3  [[[tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.,...  Futurama_character02  \n",
       "4  [[[tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.,...  Futurama_character02  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_dict = {}\n",
    "i = 0\n",
    "for language in os.listdir(\"./data\"):\n",
    "    for char in os.listdir(\"./data/{}\".format(language)):\n",
    "        for file in os.listdir(\"./data/{}/{}\".format(language, char)):\n",
    "            #Make empty data frame\n",
    "            language_dict[i] = {}\n",
    "            \n",
    "            #Bring in file information\n",
    "            language_dict[i]['language'] = language\n",
    "            language_dict[i]['char'] = char\n",
    "            language_dict[i]['file'] = file\n",
    "            language_dict[i]['path'] = \"./data/{}/{}/{}\".format(language,\n",
    "                                                                char,\n",
    "                                                                file)\n",
    "            \n",
    "            #Image to array\n",
    "            img = Image.open(language_dict[i]['path']).convert(\"L\")\n",
    "            img = np.array(img)\n",
    "            language_dict[i]['image_array'] = img\n",
    "            \n",
    "            #Import image as tensor\n",
    "            image = Image.open(language_dict[i]['path'])\n",
    "            image = transforms.ToTensor()(image).unsqueeze(0) # unsqueeze to add artificial first dimension\n",
    "            image = Variable(image)\n",
    "            language_dict[i]['image_tensor'] = image\n",
    "            \n",
    "            #Add onto index\n",
    "            i += 1\n",
    "\n",
    "#Set and name dataframe\n",
    "omni = pd.DataFrame.from_dict(language_dict).T\n",
    "\n",
    "#build target column\n",
    "omni[\"target\"] = omni[\"language\"] + \"_\" + omni[\"char\"]\n",
    "omni.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:06:29.796956Z",
     "start_time": "2019-08-14T03:06:29.768507Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = omni[[x for x in omni.columns if x is not \"target\"]]\n",
    "y = omni[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:06:47.503029Z",
     "start_time": "2019-08-14T03:06:47.496715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10712"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:07:53.106518Z",
     "start_time": "2019-08-14T03:07:53.104276Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tradition = X_train[\"image_array\"]\n",
    "X_test_tradition = X_test[\"image_array\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T01:39:21.292644Z",
     "start_time": "2019-08-14T01:39:21.285307Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.Resize(omni_dim),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomRotation(10),\n",
    "                                      transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "                                      transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(omni_dim),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "# training_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "# validation_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    " \n",
    "# training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True)\n",
    "# validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:25:22.778681Z",
     "start_time": "2019-08-14T03:08:30.728809Z"
    }
   },
   "outputs": [],
   "source": [
    "#Make sure to delete training folder in advance\n",
    "os.system('mkdir ./training')\n",
    "for x in X_train.index:\n",
    "    path = X_train.path.loc[x]\n",
    "    new = X_train.file.loc[x]\n",
    "    os.system('cp {} ./training/{}'.format(path, new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T03:33:26.011801Z",
     "start_time": "2019-08-14T03:25:22.780191Z"
    }
   },
   "outputs": [],
   "source": [
    "os.system('mkdir ./test')\n",
    "for x in X_test.index:\n",
    "    path = X_test.path.loc[x]\n",
    "    new = X_test.file.loc[x]\n",
    "    os.system('cp {} ./test/{}'.format(path, new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T08:59:08.559109Z",
     "start_time": "2019-08-14T08:59:08.547883Z"
    }
   },
   "outputs": [],
   "source": [
    "def labeldict(df):\n",
    "    labels = df.file.apply(lambda a: str(a).split(\"_\")[0]) + \"_\" + df.language\n",
    "    print(\"Number of labels in dataframe: {}\".format(labels.nunique()))\n",
    "    return dict(zip(range(len(labels)), sorted(labels.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T09:03:40.318541Z",
     "start_time": "2019-08-14T09:03:40.314515Z"
    }
   },
   "outputs": [],
   "source": [
    "###BELOW IS IN PROGRESS###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T08:59:17.653415Z",
     "start_time": "2019-08-14T08:59:17.597435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels in dataframe: 1623\n"
     ]
    }
   ],
   "source": [
    "labels = labeldict(X_test)\n",
    "\n",
    "image_size = 28\n",
    "num_classes = 10\n",
    "num_channels = 1\n",
    "batch_size = 64\n",
    "id_to_label ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T08:38:13.843370Z",
     "start_time": "2019-08-14T08:38:13.820555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19834    0001_01.png\n",
       "19829    0001_02.png\n",
       "19837    0001_03.png\n",
       "19832    0001_04.png\n",
       "19825    0001_05.png\n",
       "            ...     \n",
       "6351     1623_13.png\n",
       "6357     1623_14.png\n",
       "6355     1623_16.png\n",
       "6345     1623_17.png\n",
       "6340     1623_19.png\n",
       "Name: file, Length: 21748, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.file.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "num_classes = 10\n",
    "num_channels = 1\n",
    "batch_size = 64\n",
    "id_to_label = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "198.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
